"use client";

import React, { useEffect, useState, useCallback, useRef } from "react";
import { useAuth } from "@/hooks/useAuth";
import { useSSE } from "@/components/SSEProvider";
import { config } from "@/config";
import VideoResultModal from "@/components/video-result-modal";
import { useRouter, useSearchParams } from "next/navigation";
import { VideoList } from "@/components/video/VideoList";
import {
  TaskItem,
  BackendResponse,
  TaskListData,
} from "@/services/types/video.types";
import { ChatInput } from "@/components/input/ChatInput";
import { VideoGenerationParams } from "@/services/types/input.types";
import type { VideoOptions, GenerationMode } from "@/lib/types";
import { getResolutionProfile, getI2VResolutionProfile } from "@/lib/types";
import { VideoGenerationChatBar } from "@/components/VideoGenerationChatBar";
import { api } from "@/lib/auth/apiClient";
import type { ImageItem } from "@/services/types/image.types";
import { toast } from "sonner";
import { useTranslations } from "next-intl";
import { LoginModal } from "@/components/login-modal";
import { LogIn } from "lucide-react";
import { Button } from "@/components/ui/button";

export default function CreatePage() {
  const t = useTranslations("VideoCreation");
  const router = useRouter();
  const searchParams = useSearchParams();
  const taskId = searchParams.get("taskId"); // URLì—ì„œ taskId ì½ê¸°
  const { isLoggedIn, userName, memberId } = useAuth();
  const { isConnected, notifications } = useSSE(); // lastNotification ì œê±°

  //   const listRef = useRef(null)
  const [isGenerating, setIsGenerating] = useState(false);
  // const [taskList, setTaskList] = useState<TaskItem[]>([]);
  const [taskList, setTaskList] = useState<TaskItem[]>([]);
  const [lastFetchTime, setLastFetchTime] = useState("");

  // ëª¨ë¸ ê´€ë ¨ ìƒíƒœ
  const [availableModels, setAvailableModels] = useState<any[]>([]);

  const [selectedTab, setSelectedTab] = useState("STYLE"); // ë˜ëŠ” "CHARACTER"
  const [styleModels, setStyleModels] = useState<any[]>([]);
  const [characterModels, setCharacterModels] = useState<any[]>([]);

  // ë¬´í•œ ìŠ¤í¬ë¡¤ ê´€ë ¨ ìƒíƒœ ì¶”ê°€
  const [loading, setLoading] = useState(false);
  const [hasMore, setHasMore] = useState(true);
  const [nextCursor, setNextCursor] = useState<string | null>(null);

  // ê¸°ì¡´ ìƒíƒœë“¤ ì•„ë˜ì— ì¶”ê°€
  const [selectedResolution, setSelectedResolution] = useState<"720p" | "480p">(
    "720p"
  );
  const [selectedAspectRatio, setSelectedAspectRatio] = useState<
    "1:1" | "16:9" | "9:16"
  >("16:9");
  const [selectedFrames, setSelectedFrames] = useState(81);

  // taskIdê°€ ìˆìœ¼ë©´ í•´ë‹¹ ì˜ìƒ ì°¾ê¸°
  const selectedTask = taskId
    ? taskList.find((item) => item.task.id.toString() === taskId.toString())
    : null;

  // ëª¨ë¸ ëª©ë¡ ë¶ˆëŸ¬ì˜¤ê¸° - ë°±ì—”ë“œ ì‘ë‹µ êµ¬ì¡°ì— ë§ê²Œ ìˆ˜ì •
  const fetchAvailableModels = async () => {
    try {
      // STYLE ëª¨ë¸ ì¡°íšŒ
      const styleResponse = await api.get(
        `${config.apiUrl}/api/weights?mediaType=VIDEO&styleType=STYLE&modelType=LORA`
      );

      if (styleResponse.ok) {
        const styleData = await styleResponse.json();
        const styleModels = styleData.data || styleData; // ë°±ì—”ë“œ ì‘ë‹µ êµ¬ì¡°ì— ë”°ë¼ ì²˜ë¦¬
        setStyleModels(styleModels);
        console.log("ğŸ¨ Style Models API Response:", styleData);
        console.log("ğŸ¨ Style Models Array:", styleModels);
        if (styleModels.length > 0) {
          console.log("ğŸ¨ First Style Model Structure:", styleModels[0]);
        }
      }

      // CHARACTER ëª¨ë¸ ì¡°íšŒ
      const characterResponse = await api.get(
        `${config.apiUrl}/api/weights?mediaType=VIDEO&styleType=CHARACTER&modelType=LORA`
      );

      if (characterResponse.ok) {
        const characterData = await characterResponse.json();
        const characterModels = characterData.data || characterData;
        setCharacterModels(characterModels);
        console.log("ğŸ‘¤ Character Models API Response:", characterData);
        console.log("ğŸ‘¤ Character Models Array:", characterModels);
        if (characterModels.length > 0) {
          console.log("ğŸ‘¤ First Character Model Structure:", characterModels[0]);
        }
      }

      // ì „ì²´ ëª¨ë¸ ëª©ë¡ ì„¤ì • (í˜„ì¬ íƒ­ì— ë”°ë¼)
      const currentModels =
        selectedTab === "STYLE" ? styleModels : characterModels;
      setAvailableModels(currentModels);
    } catch (error) {
      console.error("âŒ ëª¨ë¸ ëª©ë¡ ë¡œë“œ ì‹¤íŒ¨:", error);
    }
  };

  // refë“¤
  const taskListRef = useRef<TaskItem[]>([]);
  const loadingRef = useRef(false);
  const nextCursorRef = useRef<string | null>(null);
  const hasMoreRef = useRef(true);

  // ìƒíƒœ ë™ê¸°í™”
  useEffect(() => {
    hasMoreRef.current = hasMore;
    taskListRef.current = taskList;
  }, [hasMore, taskList]);

  // ë¬´í•œ ìŠ¤í¬ë¡¤ í•¸ë“¤ëŸ¬
  useEffect(() => {
    const handleScroll = () => {
      if (loadingRef.current || !hasMoreRef.current) {
        return;
      }

      const scrollTop = document.documentElement.scrollTop;
      const scrollHeight = document.documentElement.scrollHeight;
      const clientHeight = document.documentElement.clientHeight;
      const threshold = 150;
      const isNearBottom = scrollTop + clientHeight >= scrollHeight - threshold;

      if (isNearBottom) {
        console.log("ğŸš€ ë¬´í•œ ìŠ¤í¬ë¡¤ íŠ¸ë¦¬ê±°!");
        fetchTaskList(false);
      }
    };

    let timeoutId: NodeJS.Timeout; // íƒ€ì… ëª…ì‹œ
    const debouncedHandleScroll = () => {
      clearTimeout(timeoutId);
      timeoutId = setTimeout(handleScroll, 100);
    };

    window.addEventListener("scroll", debouncedHandleScroll, { passive: true });
    return () => {
      clearTimeout(timeoutId);
      window.removeEventListener("scroll", debouncedHandleScroll);
    };
  }, []);

  // fetchTaskList - ë°±ì—”ë“œ ì‘ë‹µ êµ¬ì¡°ì— ë§ê²Œ ìˆ˜ì •
  const fetchTaskList = useCallback(async (reset = false) => {
    if (loadingRef.current) {
      console.log("âŒ ì´ë¯¸ ë¡œë”© ì¤‘ì´ë¯€ë¡œ ìš”ì²­ ë¬´ì‹œ");
      return;
    }

    loadingRef.current = true;
    setLoading(true);

    try {
      console.log("ğŸ”„ Task list ìƒˆë¡œê³ ì¹¨ ì¤‘...");

      const size = reset ? "8" : "6";
      const params = new URLSearchParams({ size });

      const currentCursor = nextCursorRef.current;
      if (!reset && currentCursor) {
        params.append("nextPageCursor", currentCursor);
        console.log(
          "ğŸ“ í˜„ì¬ ì»¤ì„œ ì „ë‹¬:",
          typeof currentCursor === "string"
            ? currentCursor.substring(0, 30) + "..."
            : currentCursor
        );
      }

      const url = `${config.apiUrl}/api/videos/task?${params}`;
      console.log("ğŸ“¡ API ìš”ì²­ URL:", url);

      const res = await api.get(url);

      if (!res.ok) {
        throw new Error(`HTTP ${res.status}: ${res.statusText}`);
      }

      // ë°±ì—”ë“œ ì‘ë‹µ êµ¬ì¡°ì— ë§ê²Œ íŒŒì‹±
      const backendResponse: BackendResponse<TaskListData> = await res.json();
      console.log("ğŸ“¦ ì „ì²´ ì‘ë‹µ:", backendResponse);

      // ë°ì´í„°ê°€ nullì¸ ê²½ìš° ì²˜ë¦¬
      if (!backendResponse.data) {
        console.log("âš ï¸ dataê°€ nullì…ë‹ˆë‹¤. ë¹ˆ ë°°ì—´ë¡œ ì²˜ë¦¬");
        if (reset) {
          setTaskList([]);
          taskListRef.current = [];
        }
        setHasMore(false);
        hasMoreRef.current = false;
        return;
      }

      const content = backendResponse.data.content || [];
      console.log("ğŸ“‹ ë°›ì€ ë°ì´í„° ê°œìˆ˜:", content.length);
      console.log(
        "ğŸ“‹ ë°›ì€ ë°ì´í„° IDë“¤:",
        content.map((item) => item.task.id)
      );
      
      // Debug dimensions from backend
      content.forEach((item) => {
        if (item.task.imageUrl) { // I2V task
          console.log(`ğŸ“ I2V Task ${item.task.id} dimensions from backend: ${item.task.width}x${item.task.height}`);
          const ratio = item.task.width / item.task.height;
          console.log(`ğŸ“ Task ${item.task.id} calculated ratio: ${ratio > 1 ? 'landscape' : ratio < 1 ? 'portrait' : 'square'}`);
        }
      });

      if (reset) {
        console.log("ğŸ”„ Reset: ì „ì²´ êµì²´");
        taskListRef.current = content;
        setTaskList(content);
      } else {
        console.log("â• Append: ê¸°ì¡´ ë°ì´í„°ì— ì¶”ê°€");
        const existingIds = new Set(taskListRef.current.map((t) => t.task.id));
        const newItems = content.filter(
          (item) => !existingIds.has(item.task.id)
        );

        console.log("ğŸ” ì‹¤ì œ ì¶”ê°€ë  ìƒˆ í•­ëª©:", newItems.length, "ê°œ");

        if (newItems.length === 0 && content.length > 0) {
          console.warn("âš ï¸ ì¤‘ë³µ ë°ì´í„° - hasMoreë¥¼ falseë¡œ ì„¤ì •");
          setHasMore(false);
          hasMoreRef.current = false;
          return;
        }

        const updatedList = [...taskListRef.current, ...newItems];
        taskListRef.current = updatedList;
        setTaskList(updatedList);
      }

      // ì»¤ì„œ ì²˜ë¦¬
      const newNextCursor = backendResponse.data.nextPageCursor;
      console.log("ğŸ” ìƒˆ ì»¤ì„œ:", newNextCursor ? "ìˆìŒ" : "ì—†ìŒ");

      setNextCursor(newNextCursor);
      nextCursorRef.current = newNextCursor;
      setHasMore(!!newNextCursor);
      hasMoreRef.current = !!newNextCursor;

      console.log(
        "âœ… Task list ì—…ë°ì´íŠ¸ ì™„ë£Œ:",
        content.length,
        "ê°œ í•­ëª© ë°›ìŒ"
      );
      console.log("ğŸ“Š í˜„ì¬ ì „ì²´ taskList ê¸¸ì´:", taskListRef.current.length);

      // ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸ ì‹œê°„ ì„¤ì •
      setLastFetchTime(new Date().toLocaleTimeString());
    } catch (error) {
      console.error("âŒ " + t("error.title") + ":", error);
      setHasMore(false);
      hasMoreRef.current = false;
    } finally {
      loadingRef.current = false;
      setLoading(false);
    }
  }, []);

  // ë¹„ë””ì˜¤ ì •ë³´ ê³„ì‚° ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
  const calculateAspectRatio = (width: number, height: number): string => {
    const gcd = (a: number, b: number): number => (b === 0 ? a : gcd(b, a % b));
    const divisor = gcd(width, height);
    const ratioWidth = width / divisor;
    const ratioHeight = height / divisor;
    
    // ì¼ë°˜ì ì¸ ë¹„ìœ¨ë“¤ ì²´í¬
    if (ratioWidth === ratioHeight) return "1:1";
    if (ratioWidth === 16 && ratioHeight === 9) return "16:9";
    if (ratioWidth === 9 && ratioHeight === 16) return "9:16";
    if (ratioWidth === 4 && ratioHeight === 3) return "4:3";
    if (ratioWidth === 3 && ratioHeight === 4) return "3:4";
    
    // ê·¸ ì™¸ì˜ ê²½ìš° ê³„ì‚°ëœ ë¹„ìœ¨ ë°˜í™˜
    return `${ratioWidth}:${ratioHeight}`;
  };

  const calculateDuration = (numFrames: number): string => {
    // ì¼ë°˜ì ìœ¼ë¡œ 20 FPS ê¸°ì¤€ìœ¼ë¡œ ê³„ì‚° (ë°±ì—”ë“œ ì„¤ì •ì— ë”°ë¼ ë‹¤ë¥¼ ìˆ˜ ìˆìŒ)
    // 81 frames = ~4s, 121 frames = ~6s íŒ¨í„´ìœ¼ë¡œ ë³´ì„
    if (numFrames <= 81) return "4s";
    if (numFrames <= 101) return "6s";
    
    // ë” ì •í™•í•œ ê³„ì‚°ì´ í•„ìš”í•œ ê²½ìš°
    const fps = 20; // ì¶”ì • FPS (ì‹¤ì œ ë°±ì—”ë“œ ì„¤ì • í™•ì¸ í•„ìš”)
    const seconds = Math.round(numFrames / fps);
    return `${seconds}s`;
  };

  const getResolutionLabel = (width: number, height: number): string => {
    const minDimension = Math.min(width, height);
    if (minDimension >= 720) return "720p";
    if (minDimension >= 480) return "480p";
    return `${width}x${height}`;
  };

  // aspect ratioì— ë”°ë¥¸ width, height ê³„ì‚° í•¨ìˆ˜
  const getVideoDimensions = (aspectRatio: string, quality: string) => {
    const isHD = quality === "720p";
    switch (aspectRatio) {
      case "1:1":
        return { width: isHD ? 720 : 480, height: isHD ? 720 : 480 };
      case "16:9":
        return { width: isHD ? 1280 : 854, height: isHD ? 720 : 480 };
      case "9:16":
        return { width: isHD ? 720 : 480, height: isHD ? 1280 : 854 };
      default:
        return { width: isHD ? 1280 : 854, height: isHD ? 720 : 480 };
    }
  };

  // ì´ë¯¸ì§€ í¬ê¸°ë¥¼ ê°€ì ¸ì˜¤ëŠ” ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
  const getImageDimensions = (file: File): Promise<{ width: number; height: number }> => {
    return new Promise((resolve) => {
      const img = new Image();
      img.onload = () => {
        resolve({ width: img.naturalWidth, height: img.naturalHeight });
      };
      img.src = URL.createObjectURL(file);
    });
  };

  // ì´ë¯¸ì§€ í¬ê¸°ë¥¼ í’ˆì§ˆ ì„¤ì •ì— ë§ê²Œ ì¡°ì •í•˜ëŠ” í•¨ìˆ˜
  const calculateScaledDimensions = (
    originalWidth: number,
    originalHeight: number,
    quality: string
  ) => {
    const targetSize = quality === "720p" ? 720 : 480;
    const minDimension = Math.min(originalWidth, originalHeight);
    
    // ë” ì‘ì€ ì°¨ì›ì„ ëª©í‘œ í¬ê¸°ë¡œ ë§ì¶”ê³  ë¹„ìœ¨ì„ ìœ ì§€
    const scale = targetSize / minDimension;
    const scaledWidth = Math.round(originalWidth * scale);
    const scaledHeight = Math.round(originalHeight * scale);
    
    return { width: scaledWidth, height: scaledHeight };
  };

  // VideoGenerationUIì—ì„œ ì‚¬ìš©í•  ìƒˆë¡œìš´ í•¸ë“¤ëŸ¬
  const handleVideoGeneration = async (
    prompt: string,
    mode: GenerationMode,
    options: VideoOptions,
    uploadedImageFile?: File,
    libraryImageData?: { imageItem: ImageItem; imageUrl: string }
  ) => {
    setIsGenerating(true);

    // Get lora model with fallback
    const selectedLoraModel = options.style || options.character;
    
    const tempId = Date.now();
    // Calculate dimensions for optimistic task display
    let tempWidth: number = 1280; // Default fallback
    let tempHeight: number = 720; // Default fallback
    let tempFrames: number;
    
    if (mode === "i2v" && (uploadedImageFile || libraryImageData)) {
      if (libraryImageData) {
        // Use existing dimensions from library image
        tempWidth = libraryImageData.imageItem.task.width || 1280;
        tempHeight = libraryImageData.imageItem.task.height || 720;
      } else if (uploadedImageFile) {
        // Calculate dimensions from uploaded file
        const imageDimensions = await getImageDimensions(uploadedImageFile);
        const scaledDimensions = calculateScaledDimensions(
          imageDimensions.width,
          imageDimensions.height,
          options.quality
        );
        tempWidth = scaledDimensions.width;
        tempHeight = scaledDimensions.height;
      }
    } else {
      // For T2V mode, use aspect ratio dimensions
      const dimensions = getVideoDimensions(options.aspectRatio, options.quality);
      tempWidth = dimensions.width;
      tempHeight = dimensions.height;
    }
    
    tempFrames = options.duration === 4 ? 81 : 101;

    const optimisticTask: TaskItem = {
      type: "video",
      task: {
        id: tempId,
        prompt: prompt,
        lora: mode === "t2v" ? (selectedLoraModel?.name || "studio ghibli style") : null,
        imageUrl: mode === "i2v" ? (libraryImageData?.imageUrl || null) : null,
        height: tempHeight,
        width: tempWidth,
        numFrames: tempFrames,
        status: "IN_PROGRESS",
        runpodId: null,
        createdAt: new Date().toISOString(),
      },
      image: null,
    };

    setTaskList((prev) => [optimisticTask, ...prev]);

    try {
      const endpoint = mode === "t2v" 
        ? "/api/videos/create/t2v" 
        : libraryImageData 
          ? "/api/videos/create/i2v/v2"  // Library image uses v2 endpoint
          : "/api/videos/create/i2v";     // Computer upload uses original endpoint

      // Width/height no longer needed for API payload

      const frames =
        options.duration === 4 ? 81 : 101;

      // Get lora ID with fallback to default (1 is Studio Ghibli based on API response)
      const loraId = selectedLoraModel?.id || 1; // Default to Studio Ghibli (id: 1)

      let response: Response;

      if (mode === "i2v" && (uploadedImageFile || libraryImageData)) {
        let resolutionProfile: string;
        let requestData: any;
        
        if (libraryImageData) {
          // Library image case - use JSON payload with imageUrl for v2 endpoint
          const imageWidth = libraryImageData.imageItem.task.width || 1280;
          const imageHeight = libraryImageData.imageItem.task.height || 720;
          resolutionProfile = getI2VResolutionProfile(
            imageWidth,
            imageHeight,
            options.quality
          );
          
          console.log(`ğŸ“ I2V Library Image dimensions: ${imageWidth}x${imageHeight}`);
          console.log(`ğŸ“ I2V Resolution profile: ${resolutionProfile}`);
          console.log(`ğŸ–¼ï¸ Library Image URL: ${libraryImageData.imageUrl}`);
          
          // Create JSON payload for v2 endpoint
          requestData = {
            prompt: prompt,
            imageUrl: libraryImageData.imageUrl,
            resolutionProfile: resolutionProfile,
            numFrames: frames
          };
          
          console.log("ğŸ“¦ I2V Library Request payload (JSON):", requestData);
          
        } else if (uploadedImageFile) {
          // File upload case - get actual image dimensions and calculate resolutionProfile
          const imageDimensions = await getImageDimensions(uploadedImageFile);
          resolutionProfile = getI2VResolutionProfile(
            imageDimensions.width,
            imageDimensions.height,
            options.quality
          );
          
          console.log(`ğŸ“ I2V File Image dimensions: ${imageDimensions.width}x${imageDimensions.height}`);
          console.log(`ğŸ“ I2V Resolution profile: ${resolutionProfile}`);
          
          const formData = new FormData();
          formData.append("image", uploadedImageFile);
          formData.append(
            "request",
            JSON.stringify({
              loraId: loraId,
              prompt: prompt,
              resolutionProfile: resolutionProfile,
              numFrames: frames,
            })
          );
          
          requestData = formData;
        }
        
        // Make API call based on request type
        if (libraryImageData) {
          // Library image uses JSON POST
          response = await api.post(`${config.apiUrl}${endpoint}`, requestData);
        } else {
          // File upload uses FormData POST
          response = await api.postForm(`${config.apiUrl}${endpoint}`, requestData);
        }
      } else {
        // T2V case - use resolutionProfile instead of width/height
        const resolutionProfile = getResolutionProfile(options.aspectRatio, options.quality);
        
        const requestData = {
          prompt: prompt,
          loraId: loraId,
          resolutionProfile: resolutionProfile,
          numFrames: frames,
        };
        
        console.log("ğŸ“¦ T2V Request payload with resolutionProfile:", requestData);
        
        response = await api.post(`${config.apiUrl}${endpoint}`, requestData);
      }

      if (response.ok) {
        const backendResponse: BackendResponse<any> = await response.json();
        console.log("âœ… ë¹„ë””ì˜¤ ìƒì„± ìš”ì²­ ì„±ê³µ!", backendResponse);

        // Unlock the input immediately after successful submission
        setIsGenerating(false);

        // const checkInterval = setInterval(() => {
        //   console.log("ğŸ”„ ìƒíƒœ í™•ì¸ì„ ìœ„í•´ fetchTaskList í˜¸ì¶œ");
        //   fetchTaskList(true);
        // }, 5000);

        // setTimeout(() => {
        //   clearInterval(checkInterval);
        //   console.log("â° ì£¼ê¸°ì  í™•ì¸ ì¤‘ë‹¨");
        // }, 30000);
      } else {
        console.error("âŒ API ìš”ì²­ ì‹¤íŒ¨:", response.statusText);
        
        // Handle different error status codes
        if (response.status === 500) {
          toast.error(t("toast.serverError"));
        } else if (response.status === 400) {
          toast.error(t("toast.invalidRequest"));
        } else if (response.status === 401) {
          toast.error(t("toast.authFailed"));
        } else {
          toast.error(`Video generation failed (Error ${response.status}). Please try again.`);
        }
        
        setTaskList((prev) => prev.filter((task) => task.task.id !== tempId));
        setIsGenerating(false);
      }
    } catch (e) {
      console.error("âŒ ë„¤íŠ¸ì›Œí¬ ì—ëŸ¬:", e);
      toast.error(t("toast.networkError"));
      setTaskList((prev) => prev.filter((task) => task.task.id !== tempId));
      setIsGenerating(false);
    }
  };


  // ì´ˆê¸° ë°ì´í„° ë¡œë“œ
  useEffect(() => {
    if (isLoggedIn) {
      console.log("ğŸš€ ì´ˆê¸° ë°ì´í„° ë¡œë“œ ì‹œì‘");
      fetchTaskList(true);
      fetchAvailableModels();
      console.log("âœ… ì´ˆê¸° ë¡œë”© ì™„ë£Œ");
    }
  }, [isLoggedIn]);

  // íƒ­ ë³€ê²½ ì‹œ ëª¨ë¸ ëª©ë¡ ì—…ë°ì´íŠ¸
  useEffect(() => {
    const currentModels =
      selectedTab === "STYLE" ? styleModels : characterModels;
    setAvailableModels(currentModels);
  }, [selectedTab, styleModels, characterModels]);

  // SSE ì•Œë¦¼ì„ ë°›ì•˜ì„ ë•Œ ìƒˆë¡œê³ ì¹¨ ì²˜ë¦¬ë¥¼ ìœ„í•œ ì´ë²¤íŠ¸ ë¦¬ìŠ¤ë„ˆ
  useEffect(() => {
    const handleVideoCompleted = () => {
      console.log(
        "ğŸ¬ Create í˜ì´ì§€: ë¹„ë””ì˜¤ ìƒì„± ì™„ë£Œ ì•Œë¦¼ ë°›ìŒ! ë°ì´í„° ìƒˆë¡œê³ ì¹¨..."
      );
      fetchTaskList(true);
      setIsGenerating(false);
    };

    const handleImageCompleted = () => {
      console.log(
        "ğŸ–¼ï¸ Create í˜ì´ì§€: ì´ë¯¸ì§€ ìƒì„± ì™„ë£Œ ì•Œë¦¼ ë°›ìŒ! ë°ì´í„° ìƒˆë¡œê³ ì¹¨..."
      );
      fetchTaskList(true);
      setIsGenerating(false);
    };

    const handleUpscaleCompleted = () => {
      console.log(
        "â¬†ï¸ Create í˜ì´ì§€: ì—…ìŠ¤ì¼€ì¼ ì™„ë£Œ ì•Œë¦¼ ë°›ìŒ! ë°ì´í„° ìƒˆë¡œê³ ì¹¨..."
      );
      fetchTaskList(true);
      setIsGenerating(false);
    };

    // ìœˆë„ìš° ì´ë²¤íŠ¸ ë¦¬ìŠ¤ë„ˆ ë“±ë¡
    window.addEventListener("videoCompleted", handleVideoCompleted);
    window.addEventListener("imageCompleted", handleImageCompleted);
    window.addEventListener("upscaleCompleted", handleUpscaleCompleted);

    return () => {
      // cleanup
      window.removeEventListener("videoCompleted", handleVideoCompleted);
      window.removeEventListener("imageCompleted", handleImageCompleted);
      window.removeEventListener("upscaleCompleted", handleUpscaleCompleted);
    };
  }, [fetchTaskList]);

  const handleMediaClick = (clickedItem: TaskItem) => {
    router.push(`/create/videos?taskId=${clickedItem.task.id}`);
  };

  const handleCopyPrompt = async (item: TaskItem) => {
    try {
      await navigator.clipboard.writeText(item.task.prompt);
      console.log("Copied prompt:", item.task.prompt);
      toast.success(t("toast.promptCopied"));
    } catch (error) {
      console.error("Failed to copy:", error);
      toast.error(t("toast.copyFailed"));
    }
  };

  const handleDownload = async (item: TaskItem) => {
    if (!item.image?.url) return;

    try {
      console.log("Starting download for task:", item.task.id);
      
      // Use the download API route with the video URL
      const filename = `video-${item.task.id}.mp4`;
      const downloadApiUrl = `/api/download?url=${encodeURIComponent(item.image.url)}&filename=${encodeURIComponent(filename)}`;
      
      const link = document.createElement('a');
      link.href = downloadApiUrl;
      link.download = filename;
      link.style.display = 'none';
      
      document.body.appendChild(link);
      link.click();
      document.body.removeChild(link);
      
      console.log("âœ… Download initiated for task:", item.task.id);
      toast.success(t("toast.downloadStarted"));
      
    } catch (error) {
      console.error("âŒ Download failed:", error);
      toast.error(t("toast.downloadFailed"));
    }
  };

  const handleDelete = async (item: TaskItem) => {
    // Confirmation dialog
    const shortPrompt = item.task.prompt.length > 50 ? item.task.prompt.substring(0, 50) + '...' : item.task.prompt;
    if (!confirm(t("delete.confirm") + "\n\n" + shortPrompt)) {
      return;
    }

    try {
      console.log("Deleting task:", item.task.id);
      
      const response = await api.delete(`${config.apiUrl}/api/videos/${item.task.id}`);
      
      if (response.ok) {
        // Remove from local state immediately
        setTaskList((prev) => prev.filter((task) => task.task.id !== item.task.id));
        
        toast.success(t("delete.success"));
        console.log("âœ… Successfully deleted task:", item.task.id);
        
        // Refresh the list to ensure consistency
        fetchTaskList(true);
      } else {
        throw new Error(`Delete failed: ${response.status}`);
      }
    } catch (error) {
      console.error("âŒ Delete failed:", error);
      
      // Check if it's a constraint violation error
      const errorMessage = error instanceof Error ? error.message : String(error);
      if (errorMessage.includes('constraint') || errorMessage.includes('foreign key')) {
        toast.error(t("delete.constraintError"));
      } else {
        toast.error(t("delete.failed"));
      }
    }
  };

  const handleEnhancePrompt = async (prompt: string, selections: VideoOptions): Promise<string> => {
    console.log("Enhancing prompt:", prompt);
    
    try {
      // Get the selected lora model
      const selectedLoraModel = selections.style || selections.character;
      
      // Build request payload - only include loraId if a lora model is selected
      const requestPayload: any = {
        prompt: prompt
      };
      
      if (selectedLoraModel?.id) {
        requestPayload.loraId = selectedLoraModel.id;
        console.log("Using lora ID:", selectedLoraModel.id, "for prompt:", prompt);
      } else {
        console.log("No lora model selected, enhancing prompt without loraId");
      }
      
      const response = await api.post(`${config.apiUrl}/api/weights`, requestPayload);
      
      if (response.ok) {
        const backendResponse: BackendResponse<string> = await response.json();
        console.log("âœ… Prompt enhanced successfully!", backendResponse);
        
        // Return the enhanced prompt from the response
        return backendResponse.data || prompt; // Fallback to original prompt if data is null
      } else {
        console.error("âŒ API request failed:", response.statusText);
        throw new Error(`Failed to enhance prompt: ${response.statusText}`);
      }
    } catch (error) {
      console.error("âŒ Network error:", error);
      throw new Error("Failed to enhance prompt");
    }
  };

  const handleCloseModal = () => {
    // URLì—ì„œ taskId ì œê±°
    router.push("/create/videos");
  };

  if (!isLoggedIn) {
    return (
      <>
        <div className="flex items-center justify-center min-h-screen">
          <p className="text-muted-foreground">{t("loginRequired")}</p>
        </div>
        <LoginModal
          isOpen={true}
          onClose={() => router.push('/home')}
        />
      </>
    );
  }

  return (
    <>
      <VideoList
        taskList={taskList}
        loading={loading}
        hasMore={hasMore}
        onVideoClick={handleMediaClick}
        onCopyPrompt={handleCopyPrompt}
        onDownload={handleDownload}
        onDelete={handleDelete}
      />
      <VideoGenerationChatBar
        onSubmit={handleVideoGeneration}
        isGenerating={isGenerating}
        availableModels={availableModels}
        styleModels={styleModels}
        characterModels={characterModels}
        onEnhancePrompt={handleEnhancePrompt}
      />
      {/* âœ… URL ê¸°ë°˜ ëª¨ë‹¬ */}
      {selectedTask && (() => {
        // ë””ë²„ê¹…ì„ ìœ„í•œ ì½˜ì†” ë¡œê·¸
        console.log("ğŸ¬ Selected Task Data:", selectedTask);
        console.log("ğŸ“ Task width:", selectedTask.task.width);
        console.log("ğŸ“ Task height:", selectedTask.task.height);
        console.log("â±ï¸ Task numFrames:", selectedTask.task.numFrames);
        
        const aspectRatio = calculateAspectRatio(selectedTask.task.width, selectedTask.task.height);
        const duration = calculateDuration(selectedTask.task.numFrames);
        const resolution = getResolutionLabel(selectedTask.task.width, selectedTask.task.height);
        
        console.log("ğŸ¯ Calculated aspect ratio:", aspectRatio);
        console.log("ğŸ¯ Calculated duration:", duration);
        console.log("ğŸ¯ Calculated resolution:", resolution);
        
        return (
          <VideoResultModal
            isOpen={true}
            onClose={handleCloseModal}
            videoResult={{
              src: selectedTask.image?.url || "",
              prompt: selectedTask.task.prompt,
              inputImageUrl: selectedTask.task.imageUrl || undefined,
              parameters: {
                "Aspect Ratio": aspectRatio,
                Duration: duration,
                Style: selectedTask.task.lora || "Default",
                Resolution: resolution,
                "Task ID": selectedTask.task.id.toString(),
                "Created At": new Date(
                  selectedTask.task.createdAt
                ).toLocaleDateString(),
              },
            }}
          />
        );
      })()}
    </>
  );
}
